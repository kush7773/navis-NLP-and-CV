# Navis Robot - NLP & Computer Vision

ğŸ¤– Advanced humanoid robot with AI conversation, voice control, computer vision, and autonomous following capabilities.

## âœ¨ Features

### ğŸ¤ Voice Control
- Voice-activated commands via phone microphone
- "Follow me Navis" - Activate camera-based human tracking
- "Stop Navis" - Stop following
- Natural language conversation via Groq AI

### ğŸ“¹ Computer Vision
- Live camera feed with face detection
- Real-time human tracking and following
- Bounding box visualization
- Toggle face detection on/off

### ğŸ•¹ï¸ Manual Control
- Professional web-based joystick interface
- Touch-friendly controls (F/B/L/R/S)
- Emergency stop button
- Responsive design (mobile + desktop)

### ğŸ¤– AI Integration
- **Groq API** - Ultra-fast, free LLM (primary)
- **Hugging Face** - Free alternative with 100+ models
- Natural conversation capabilities
- Voice-to-text and text-to-speech

### ğŸ¨ Professional UI
- Dark cyberpunk theme
- Real-time status indicators
- Glowing animations
- All-in-one control center

## ğŸ—ï¸ Architecture

```
Raspberry Pi (Master)
â”œâ”€â”€ Python Control Programs
â”‚   â”œâ”€â”€ navis_complete_control.py (Main interface)
â”‚   â”œâ”€â”€ navis_hybrid.py (Camera & CV)
â”‚   â””â”€â”€ voice_follow_integration.py (Voice control)
â”œâ”€â”€ serial_bridge.py (Communication)
â””â”€â”€ ESP32 (Slave) via USB Serial
    â”œâ”€â”€ Motor Controller (Arduino)
    â””â”€â”€ GPIO â†’ Motor Driver â†’ DC Motors
```

## ğŸš€ Quick Start

### 1. Hardware Setup
- Raspberry Pi 4 (or 3B+)
- ESP32 microcontroller
- Motor driver (L298N/BTS7960)
- 2x DC motors
- Camera module
- Servo motor (for mouth animation)

### 2. Install Dependencies

```bash
cd /path/to/navis-NLP-and-CV
chmod +x setup_navis.sh
./setup_navis.sh
```

### 3. Configure

Edit `config.py`:
```python
GROQ_API_KEY = "your_groq_api_key_here"
RASPBERRY_PI_IP = "your_pi_ip_address"
SERIAL_PORT = "/dev/ttyUSB0"  # Your ESP32 port
```

### 4. Upload ESP32 Code

1. Open Arduino IDE
2. Install ESP32 board support
3. Open `esp32_motor_controller/esp32_motor_controller.ino`
4. Upload to ESP32

### 5. Run

```bash
python3 navis_complete_control.py
```

Access from phone: `http://your_pi_ip:5000`

## ğŸ“ Project Structure

```
navis-NLP-and-CV/
â”œâ”€â”€ navis_complete_control.py    # Main control interface
â”œâ”€â”€ navis_hybrid.py               # Camera & face tracking
â”œâ”€â”€ voice_follow_integration.py   # Voice-activated following
â”œâ”€â”€ serial_bridge.py              # ESP32 communication
â”œâ”€â”€ llm_handler_updated.py        # Groq + HuggingFace LLM
â”œâ”€â”€ tts.py                        # Text-to-speech
â”œâ”€â”€ stt.py                        # Speech-to-text
â”œâ”€â”€ servo_mouth.py                # Mouth animation
â”œâ”€â”€ config.py                     # Configuration
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ complete_control.html     # Professional UI
â”œâ”€â”€ esp32_motor_controller/
â”‚   â””â”€â”€ esp32_motor_controller.ino # ESP32 Arduino code
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ setup_navis.sh               # Auto-setup script
â”œâ”€â”€ QUICKSTART.md                # Quick start guide
â”œâ”€â”€ ESP32_SETUP_GUIDE.md         # ESP32 setup instructions
â”œâ”€â”€ CONTROL_INTERFACE_GUIDE.md   # UI guide
â”œâ”€â”€ TESTING_GUIDE.md             # Testing instructions
â””â”€â”€ README.md                    # This file
```

## ğŸ® Controls

### Joystick Commands
- **â†‘ (F)** - Forward
- **â†“ (B)** - Backward
- **â† (L)** - Turn left
- **â†’ (R)** - Turn right
- **Center (S)** - Stop
- **ğŸ›‘ Emergency Stop** - Instant stop

### Voice Commands
- "Follow me Navis" - Activate tracking
- "Stop Navis" - Stop following
- Any question - AI responds

## ğŸ”§ Hardware Connections

### ESP32 Pins
```
GPIO 32 â†’ Left Motor Forward (RPWM)
GPIO 33 â†’ Left Motor Backward (LPWM)
GPIO 25 â†’ Right Motor Forward (RPWM)
GPIO 26 â†’ Right Motor Backward (LPWM)
```

### Raspberry Pi
```
GPIO 12 â†’ Servo Motor (mouth animation)
USB â†’ ESP32 (serial communication)
Camera â†’ CSI/USB port
```

## ğŸ§ª Testing

Run component tests:
```bash
python3 test_robot.py
```

This tests:
- Config loading
- ESP32 connection
- Motor control
- Groq API
- Camera
- TTS/STT
- Flask server

## ğŸ“¡ Communication Protocol

**Raspberry Pi â†’ ESP32**:
```
Format: "LEFT,RIGHT\n"
Example: "100,-100\n" (turn right)
Range: -255 to 255
```

## ğŸ¯ API Keys

### Groq (Required)
1. Sign up: https://console.groq.com
2. Get API key
3. Add to `config.py`

### Hugging Face (Optional)
1. Sign up: https://huggingface.co
2. Get token: https://huggingface.co/settings/tokens
3. Add to `config.py`

## ğŸ› Troubleshooting

### ESP32 Not Found
```bash
ls /dev/ttyUSB* /dev/ttyACM*
# Update SERIAL_PORT in config.py
```

### Motors Don't Move
- Check power supply
- Verify pin connections
- Test ESP32 with Serial Monitor
- Check motor driver enable pin

### Camera Not Working
```bash
python3 -c "import cv2; print(cv2.VideoCapture(0).isOpened())"
```

### API Errors
- Verify API key in `config.py`
- Check internet connection
- Test with: `python3 -c "from llm_handler_updated import get_llm; print(get_llm().ask('Hello'))"`

## ğŸ“š Documentation

- **[QUICKSTART.md](QUICKSTART.md)** - Quick start guide
- **[ESP32_SETUP_GUIDE.md](ESP32_SETUP_GUIDE.md)** - ESP32 setup
- **[CONTROL_INTERFACE_GUIDE.md](CONTROL_INTERFACE_GUIDE.md)** - UI guide
- **[TESTING_GUIDE.md](TESTING_GUIDE.md)** - Testing guide

## ğŸ¨ Features Showcase

### Professional UI
- Dark cyberpunk theme with blue/purple gradients
- Real-time camera feed with face detection
- Virtual joystick with touch support
- Voice control with hold-to-record
- Emergency stop button
- Status indicators

### AI Capabilities
- Natural language conversation
- Voice-activated commands
- Context-aware responses
- Ultra-fast response times (Groq)

### Computer Vision
- Face detection and tracking
- Real-time video streaming
- Human following mode
- Visual tracking indicators

## ğŸ” Security Notes

**Important**: 
- Keep API keys private
- Don't commit `config.py` with real keys
- Use environment variables in production
- Secure your network connection

## ğŸ“„ License

MIT License - Feel free to use and modify!

## ğŸ‘¥ Credits

**Team Robomanthan**
- Advanced robotics and AI integration
- Computer vision and autonomous navigation
- Voice control and NLP capabilities

## ğŸš€ Future Enhancements

- [ ] Object detection (not just faces)
- [ ] Path planning and obstacle avoidance
- [ ] Multi-person tracking
- [ ] Gesture recognition
- [ ] Voice wake word detection
- [ ] Mobile app (native iOS/Android)
- [ ] Cloud integration
- [ ] Advanced AI personalities

## ğŸ“ Support

For issues or questions:
1. Check documentation files
2. Run `python3 test_robot.py`
3. Review troubleshooting section
4. Open GitHub issue

---

**Built with â¤ï¸ by Team Robomanthan**

ğŸ¤– Making robots smarter, one line of code at a time!
